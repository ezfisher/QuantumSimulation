{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torchvision.transforms as T\n",
    "import torch.utils.data as data\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2 as cv\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quantum inspired computer vision\n",
    "\n",
    "reimagining 3 color channels as information for 8-state qudits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_directory = '/home/shiva/data/StockImages/'\n",
    "image_paths = glob.glob(root_directory + '*.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = T.Compose([\n",
    "    T.ToTensor(),\n",
    "    T.Resize((256, 256), antialias=False)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(data.Dataset):\n",
    "    def __init__(self, root_directory, transforms=T.ToTensor(), nchannels=3):\n",
    "        self.images = glob.glob(root_directory + '*.jpg')\n",
    "        self.transforms = transforms\n",
    "        self.nchannels = nchannels\n",
    "        self.bases = self.__make_bases__()\n",
    "    \n",
    "    def __new_order_of_magnitude__(self, size):\n",
    "        zeros = torch.zeros((size, 1))\n",
    "        ones = torch.ones((size, 1))\n",
    "        return torch.cat((zeros, ones), dim=0)\n",
    "    \n",
    "    def __make_bases__(self):\n",
    "        nstates = 2\n",
    "        bases = torch.arange(nstates).reshape((nstates, 1))\n",
    "        while bases.shape[1] < self.nchannels:\n",
    "            new_order = self.__new_order_of_magnitude__(bases.shape[0])\n",
    "            bases = torch.cat((bases, bases), dim=0)\n",
    "            bases = torch.cat((new_order, bases), dim=1)\n",
    "        return bases.type(torch.int)\n",
    "    \n",
    "    def __zeros_ones__(self, img):\n",
    "        return torch.stack((img, 1-img), dim=0)\n",
    "\n",
    "    def quantum_tensors(self, img):\n",
    "        X = self.__zeros_ones__(img)\n",
    "        Xq = torch.stack([\n",
    "            X[b[0], :, :, :] + X[b[1], :, :, :] + X[b[2], :, :, :]\n",
    "            for b in self.bases], dim=0\n",
    "        )\n",
    "        return Xq\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        img = cv.imread(self.images[index])\n",
    "        img = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n",
    "        img = cv.resize(img, (256, 256))\n",
    "        img = self.transforms(img)\n",
    "        # img = self.quantum_tensors(img)\n",
    "        img = self.__zeros_ones__(img)\n",
    "        return img\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 2, 3, 256, 256]) tensor(0.) tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "dataset = Dataset(root_directory)\n",
    "dataloader = data.DataLoader(dataset, batch_size=4, shuffle=True, drop_last=True)\n",
    "X = next(iter(dataloader))\n",
    "print(X.shape, X.min(), X.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking to entangle states\n",
    "\n",
    "Engangle 3 qubits per pixel\n",
    "\n",
    "3d analog to CX + H gate\n",
    "\n",
    "entangle pixels together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(False)\n",
      "tensor(True)\n"
     ]
    }
   ],
   "source": [
    "b2, b4 = dataset.bases[3], dataset.bases[5]\n",
    "Xq2 = torch.stack([X[:, b2[0], :, :, :], X[:, b2[1], :, :, :], X[:, b2[2], :, :, :]], dim=1)\n",
    "Xq4 = torch.stack([X[:, b4[0], :, :, :], X[:, b4[1], :, :, :], X[:, b4[2], :, :, :]], dim=1)\n",
    "\n",
    "print((Xq2==Xq4).all())\n",
    "print((Xq2.sum(dim=1)==Xq4.sum(dim=1)).all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1, 1], dtype=torch.int32) tensor([1, 0, 1], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "print(dataset.bases[3], dataset.bases[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
